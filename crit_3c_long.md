**Screening question 3c: Does the study apply the valuation methodology to a specific EO dataset or data source?**

**Includes:**

* Anything that passes 3a and 3b, and ties the valuation to a specific Earth Observation dataset.
    * **Include** e.g., Howe et al. (2022): [Comparing Sentinel-2 And Landsat 8 For Burn Severity Mapping In Western North America](https://www.mdpi.com/2072-4292/14/20/5249): this document compares performance of Sentinel-2 data against a counterfactual of Landsat-8 data to estimate a relative improvement in burn severity mapping.  This meets criterion 3c as it is comparing performance of one dataset against a counterfactual.  The resulting improvement in burn severity mapping is attributed to the improved spatial resolution of the Sentinel-2 data.
    * **Include** e.g., Fatehkia, M. et al. (2020) [The Relative Value Of Facebook Advertising Data For Poverty Mapping](https://ojs.aaai.org/index.php/ICWSM/article/view/7361): This study compares satellite data against Facebook ad data for mapping socioeconomic development in India and the Philippines.  This meets criterion 3c, as the Facebook data could be considered a counterfactual to the satellite data.  The difference in performance of poverty mapping can be attributed to the use of satellite data vs. Facebook data (though the authors frame it in the opposite direction: "we evaluate the added value of using Facebook data over satellite data...").

**Excludes:**

* Anything that passes 3a and 3b, but ties the valuation to a non-EO dataset.
    * **Exclude** e.g., Perhans, K. et al. (2014) [The value of information in conservation planning: Selecting retention trees for lichen conservation](https://www.sciencedirect.com/science/article/pii/S037811271400022X): this paper applies a Value of Information methodology to assess the value of certain types of information on trees (lichen presence, bark and stem attributes).  The valuation is not tied to an EO dataset.  Note: this paper would not have made it past Criteria 2, as there are no EO data involved - this is just included as a counterexample for Criterion 3b.
* Anything that passes 3a and 3b, but the dataset is abstract or not specifically indicated as EO.
    * **Exclude** e.g., Moltchanova, Elena et al. (2011). [The Value Of Rapid Damage Assessment For Efficient Earthquake Response](https://www.sciencedirect.com/science/article/pii/S0925753511000786): The authors develop an approach to assess the value of information on spatial damage distribution data, to improve timely arrival of response rescue teams after an earthquake.  Data on the distribution of spatial damage may be related to satellite imagery or remote observation, but this is not specifically stated in the title or abstract.

    
<!--**EXCLUDE** E.g., Rivas-Fandino, Paula et al. (2023). ["Assessment Of High Spatial Resolution Satellite Imagery For Monitoring Riparian Vegetation: Riverine Management In The Smallholding"](https://link.springer.com/article/10.1007/s10661-022-10667-8) seeks to assess the viability of satellite imagery for monitoring riparian ecosystems.  The authors show that satellite imagery can reasonably be used to estimate indices of riparian ecosystem quality, which seems valuable, but they do not offer a methodology to estimate the value of this contribution, e.g., cost effectiveness of riparian restoration.-->

